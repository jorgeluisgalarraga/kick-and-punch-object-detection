{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Player Shorts Detection Using YoloV8"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Installing YoloV8 from Ultralytics"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-08-02T16:27:18.475405Z","iopub.status.busy":"2023-08-02T16:27:18.475028Z","iopub.status.idle":"2023-08-02T16:27:37.117079Z","shell.execute_reply":"2023-08-02T16:27:37.115913Z","shell.execute_reply.started":"2023-08-02T16:27:18.475380Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os, time, random\n","import numpy as np\n","import pandas as pd\n","import cv2, torch\n","from tqdm.auto import tqdm\n","import shutil as sh\n","\n","from IPython.display import Image, clear_output, display\n","import matplotlib.pyplot as plt\n","from IPython import display\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-08-02T16:27:56.533760Z","iopub.status.busy":"2023-08-02T16:27:56.533353Z","iopub.status.idle":"2023-08-02T16:27:58.923878Z","shell.execute_reply":"2023-08-02T16:27:58.922683Z","shell.execute_reply.started":"2023-08-02T16:27:56.533726Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Ultralytics YOLOv8.0.11 ðŸš€ Python-3.10.10 torch-2.0.1 CPU\n","Setup complete âœ… (8 CPUs, 16.0 GB RAM, 250.8/926.4 GB disk)\n"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 253 ms, sys: 74.2 ms, total: 328 ms\n","Wall time: 3.6 s\n"]}],"source":["%%time\n","!pip install ultralytics==8.0.11\n","!pip install roboflow --quiet\n","!pip install roboflow\n","\n","\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from ultralytics import YOLO"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/zunushrestha/Desktop/GBC_I/Full Stack Data Science/Project\n"]}],"source":["HOME = os.getcwd()\n","print(HOME)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: /Users/zunushrestha/Desktop/GBC_I/Full: File exists\n","mkdir: Stack: File exists\n","mkdir: Data: File exists\n","mkdir: Science/Project: No such file or directory\n"]}],"source":["!mkdir {HOME}/datasets\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import os\n","\n","home_directory = \"/Users/zunushrestha/Desktop/GBC_I/Full Stack Data Science/Project\"  # Replace with your actual home directory path\n","datasets_directory = os.path.join(home_directory, \"datasets\")\n","\n","if not os.path.exists(datasets_directory):\n","    os.mkdir(datasets_directory)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/zunushrestha/Desktop/GBC_I/Full Stack Data Science/Project/datasets\n"]}],"source":["%cd {HOME}/datasets"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","Dependency ultralytics==8.0.134 is required but found version=8.0.11, to fix: `pip install ultralytics==8.0.134`\n","Downloading Dataset Version Zip in shorts-detection-1 to yolov8: 100% [5228033 / 5228033] bytes\n"]},{"name":"stderr","output_type":"stream","text":["Extracting Dataset Version Zip to shorts-detection-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 218/218 [00:00<00:00, 5275.52it/s]\n"]}],"source":["from roboflow import Roboflow\n","rf = Roboflow(api_key=\"cZJz3RNNVAC7KTWyvTm1\")\n","project = rf.workspace(\"fightdataset\").project(\"shorts-detection\")\n","dataset = project.version(1).download(\"yolov8\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.0.11 ðŸš€ Python-3.10.10 torch-2.0.1 CPU\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=shorts-detection-1/data.yaml, epochs=25, patience=50, batch=16, imgsz=800, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, retina_masks=False, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, hydra={'output_subdir': None, 'run': {'dir': '.'}}, v5loader=True, save_dir=runs/detect/train3\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.Detect                [1, [128, 256, 512]]          \n","Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/zunushrestha/Desktop/GBC_I/Full Stack Data Science/Projec\u001b[0m\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/zunushrestha/Desktop/GBC_I/Full Stack Data Science/Project/\u001b[0m\n","Image sizes 800 train, 800 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/detect/train3\u001b[0m\n","Starting training for 25 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/25         0G      1.966      6.194      2.145         27        800: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all         21         40    0.00444        0.7    0.00412    0.00122\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/25         0G      1.928      3.971      2.156         40        800: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all         21         40     0.0966      0.175     0.0621     0.0208\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/25         0G      1.874      2.704      2.107         28        800: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all         21         40      0.332        0.6      0.346      0.168\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/25         0G      1.704       2.13      1.997         26        800: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all         21         40       0.63      0.512      0.561      0.243\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/25         0G      1.629      1.832      1.924         18        800: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all         21         40      0.677      0.675      0.699      0.306\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/25         0G      1.605      1.748      1.869         34        800: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all         21         40      0.732        0.6       0.66      0.314\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/25         0G      1.504      1.305      1.743         17        800: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all         21         40      0.786      0.725      0.741      0.342\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/25         0G      1.512      1.264      1.706         22        800: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all         21         40      0.797      0.786      0.842      0.405\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/25         0G      1.424      1.156      1.662         47        800:  ^C\n","       9/25         0G      1.424      1.156      1.662         47        800:  \n","Traceback (most recent call last):\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/ultralytics/yolo/cli.py\", line 148, in entrypoint\n","    cli(cfg)\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/ultralytics/yolo/cli.py\", line 84, in cli\n","    func(cfg)\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/hydra/main.py\", line 83, in decorated_main\n","    return task_function(cfg_passthrough)\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/ultralytics/yolo/v8/detect/train.py\", line 207, in train\n","    model.train(**cfg)\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/ultralytics/yolo/engine/model.py\", line 203, in train\n","    self.trainer.train()\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py\", line 185, in train\n","    self._do_train(int(os.getenv(\"RANK\", -1)), world_size)\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py\", line 302, in _do_train\n","    preds = self.model(batch[\"img\"])\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 195, in forward\n","    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 57, in _forward_once\n","    x = m(x)  # run\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/ultralytics/nn/modules.py\", line 191, in forward\n","    return self.cv2(torch.cat(y, 1))\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/ultralytics/nn/modules.py\", line 35, in forward\n","    return self.act(self.bn(self.conv(x)))\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/Users/zunushrestha/miniconda/envs/pytorch_metal/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n","    return F.conv2d(input, weight, bias, self.stride,\n","KeyboardInterrupt\n"]}],"source":["!yolo task=detect mode=train model=yolov8s.pt data=shorts-detection-1/data.yaml epochs=25 imgsz=800 v5loader=True"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Validate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-02T16:36:59.212494Z","iopub.status.busy":"2023-08-02T16:36:59.212143Z","iopub.status.idle":"2023-08-02T16:37:23.449187Z","shell.execute_reply":"2023-08-02T16:37:23.447898Z","shell.execute_reply.started":"2023-08-02T16:36:59.212465Z"},"trusted":true},"outputs":[],"source":["!yolo task=detect mode=val model=shorts-detection-1/train/weights/best.pt data=data.yaml"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Test the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-02T16:37:23.453328Z","iopub.status.busy":"2023-08-02T16:37:23.452868Z","iopub.status.idle":"2023-08-02T16:37:24.495164Z","shell.execute_reply":"2023-08-02T16:37:24.493935Z","shell.execute_reply.started":"2023-08-02T16:37:23.453297Z"},"trusted":true},"outputs":[],"source":["!ls shorts-detection-1/test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!yolo task=detect mode=predict model=shorts-detection-1/train/weights/best.pt conf=0.5 source=shorts-detection-1/test/images"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
